{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12722722,"sourceType":"datasetVersion","datasetId":8041426},{"sourceId":12726241,"sourceType":"datasetVersion","datasetId":8043808}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"92ae03b9","cell_type":"code","source":"!pip install --upgrade transformers torch accelerate bitsandbytes unsloth --quiet","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T02:52:41.771655Z","iopub.execute_input":"2025-08-11T02:52:41.771889Z","iopub.status.idle":"2025-08-11T02:55:50.447704Z","shell.execute_reply.started":"2025-08-11T02:52:41.771866Z","shell.execute_reply":"2025-08-11T02:55:50.446932Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/47.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.7/374.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.8/306.8 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.9/511.9 kB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.4/176.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.2/821.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.1 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"id":"1285e2c2","cell_type":"code","source":"#import libraries\nimport os\nimport json\nimport torch\nfrom transformers import pipeline\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T02:56:12.597381Z","iopub.execute_input":"2025-08-11T02:56:12.597894Z","iopub.status.idle":"2025-08-11T02:56:31.540432Z","shell.execute_reply.started":"2025-08-11T02:56:12.597864Z","shell.execute_reply":"2025-08-11T02:56:31.539687Z"}},"outputs":[{"name":"stderr","text":"2025-08-11 02:56:17.962943: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754880978.131062      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754880978.179387      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"id":"d713fb97","cell_type":"code","source":"PROMPT_TEMPLATE = \"\"\"\nYou are a meticulous, unbiased English-to-Filipino Translation Quality Judge.\nYour analysis is based on a predefined, multi-dimensional rubric. Your task is to\nevaluate a given Filipino translation based on a source English text from literature.\n\nEvaluation Rubric:\n1.  Accuracy (1-5): How faithfully is the core meaning of the source text preserved?\n    - 1: Completely wrong or nonsensical.\n    - 3: Core meaning is present, but with significant errors.\n    - 5: Perfectly accurate.\n2.  Tone & Style (1-5): How well does the translation capture the original's tone (e.g., formal, ironic, gothic, conversational)?\n    - 1: Completely mismatched tone.\n    - 3: Tone is recognizable but inconsistent or flawed.\n    - 5: Perfectly captures the original style.\n3.  Nuance & Metaphor (1-5): How well are metaphors, idioms, and subtle cultural contexts handled?\n    - 1: All nuance is lost; metaphors are translated literally and nonsensically.\n    - 3: Attempts to translate nuance but misses the mark or simplifies it.\n    - 5: Nuances and metaphors are translated effectively, using cultural equivalents where necessary.\n4.  Fluency (1-5): Does the Filipino translation read naturally and fluently on its own?\n    - 1: Awkward, ungrammatical, and difficult to read.\n    - 3: Grammatically correct but sounds stiff or unnatural (\"translatorese\").\n    - 5: Perfectly fluent and natural-sounding.\n\nSource Text (English):\n\"{source_text}\"\n\nTranslation to Evaluate (Filipino):\n\"{translation_text}\"\n\nYour Task:\nProvide a quantitative score for each of the four criteria. Calculate an Overall Score by averaging the four scores. Finally, write a detailed qualitative explanation for your assessment. Your explanation must be structured, objective, and reference specific words or phrases from the texts to justify your scores.\n\nOutput strictly in the following JSON format and nothing else:\n```json\n{{\n  \"scores\": {{\n    \"accuracy\": <score>,\n    \"tone_and_style\": <score>,\n    \"nuance_and_metaphor\": <score>,\n    \"fluency\": <score>,\n    \"overall\": <average_score>\n  }},\n  \"explanation\": \"<Your detailed justification here.>\"\n}}```\n\"\"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T02:56:42.887393Z","iopub.execute_input":"2025-08-11T02:56:42.888047Z","iopub.status.idle":"2025-08-11T02:56:42.892575Z","shell.execute_reply.started":"2025-08-11T02:56:42.888025Z","shell.execute_reply":"2025-08-11T02:56:42.891856Z"}},"outputs":[],"execution_count":3},{"id":"f9f337a8","cell_type":"code","source":"def initialize_model():\n    model_id = \"unsloth/llama-3-8b-Instruct-bnb-4bit\"\n    try:\n        llm_pipeline = pipeline(\n            \"text-generation\",\n            model=model_id,\n            model_kwargs={\"torch_dtype\": \"auto\"},\n            device_map=\"auto\",\n        )\n        print(\"--- Model initialized successfully. ---\")\n        return llm_pipeline\n    except Exception as e:\n        print(f\"Error initializing model: {e}\")\n        print(\"Please ensure you have run 'pip install transformers torch accelerate' and have a stable internet connection.\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T02:56:45.509373Z","iopub.execute_input":"2025-08-11T02:56:45.509856Z","iopub.status.idle":"2025-08-11T02:56:45.515245Z","shell.execute_reply.started":"2025-08-11T02:56:45.509815Z","shell.execute_reply":"2025-08-11T02:56:45.514481Z"}},"outputs":[],"execution_count":4},{"id":"70c45783","cell_type":"code","source":"def evaluate_translation(llm_pipeline, source_text: str, translation_text: str) -> dict | None:\n    print(\"\\n--- Preparing evaluation for Baseline Judge ---\")\n    \n    prompt = PROMPT_TEMPLATE.format(\n        source_text=source_text,\n        translation_text=translation_text\n    )\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n\n    print(\"Sending prompt to local Llama 3 model...\")\n    try:\n        outputs = llm_pipeline(\n            messages,\n            max_new_tokens=1024,\n            eos_token_id=llm_pipeline.tokenizer.eos_token_id,\n            do_sample=True,\n            temperature=0.1,\n            top_p=0.9\n        )\n        llm_output_text = outputs[0]['generated_text'][-1]['content']\n    except Exception as e:\n        print(f\"An error occurred during model inference: {e}\")\n        return None\n\n    print(\"Parsing LLM response...\")\n    try:\n        # 1. Find the first opening curly brace.\n        start_index = llm_output_text.find('{')\n        # 2. Find the last closing curly brace.\n        end_index = llm_output_text.rfind('}')\n\n        if start_index == -1 or end_index == -1:\n            print(\"Error: Could not find a complete JSON object in the LLM response.\")\n            print(\"Received output:\", llm_output_text)\n            return None\n        \n        # 3. Extract the substring between them (inclusive).\n        json_string = llm_output_text[start_index : end_index + 1]\n        \n        # 4. Parse the extracted string.\n        evaluation_result = json.loads(json_string)\n        return evaluation_result\n        # -----------------------------------------------\n\n    except json.JSONDecodeError:\n        print(\"Error: Failed to decode JSON from the extracted substring.\")\n        # Print both the original output and the part we tried to parse for debugging.\n        print(\"Original received output:\", llm_output_text)\n        print(\"Extracted substring for parsing:\", json_string)\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T02:56:47.451290Z","iopub.execute_input":"2025-08-11T02:56:47.452106Z","iopub.status.idle":"2025-08-11T02:56:47.460327Z","shell.execute_reply.started":"2025-08-11T02:56:47.452077Z","shell.execute_reply":"2025-08-11T02:56:47.459684Z"}},"outputs":[],"execution_count":5},{"id":"fd9a3250-380a-4244-b206-9d1088de309c","cell_type":"code","source":"def main():\n    # --- Configuration ---\n    INPUT_CSV = '/kaggle/input/valset/Datasets - Human-Labeled Validation Set.csv'\n    OUTPUT_JSON = 'baseline_variance_subset_results.json'\n    SUBSET_LIMIT = 5  # <-- How many unique items to test\n    NUM_RUNS = 3      # <-- How many times to test each item\n\n    # Initialize the model once.\n    llm = initialize_model()\n    if not llm:\n        print(\"Aborting due to model initialization failure.\")\n        return\n\n    # Load the validation dataset.\n    try:\n        df = pd.read_csv(INPUT_CSV)\n    except FileNotFoundError:\n        print(f\"Error: Input file not found at '{INPUT_CSV}'.\")\n        return\n\n    # Limit the dataframe to the specified subset\n    df = df.head(SUBSET_LIMIT)\n\n    print(f\"\\n--- Running Baseline Judge Variance Test ---\")\n    print(f\"--- Testing {NUM_RUNS} runs on the first {len(df)} entries from {INPUT_CSV} ---\")\n    \n    all_results = []\n    # Outer loop: Iterate through each of the 5 items in the subset\n    for index, row in df.iterrows():\n        source = row.get('Source Text (English)')\n        translation = row.get('Target Text (Filipino)')\n\n        if pd.isna(source) or pd.isna(translation):\n            continue\n\n        print(f\"\\n{'='*20} Processing Entry {index + 1}/{len(df)} {'='*20}\")\n        \n        variance_runs_for_this_entry = []\n        # Inner loop: Run the evaluation NUM_RUNS times for this single item\n        for i in range(NUM_RUNS):\n            print(f\"--> Run {i + 1}/{NUM_RUNS}...\")\n            result = evaluate_translation(llm, source, translation)\n            \n            variance_runs_for_this_entry.append({\n                \"run_number\": i + 1,\n                \"evaluation_result\": result\n            })\n\n        # Append the collected variance runs for this entry to the main results list\n        all_results.append({\n            \"entry_index\": index,\n            \"source_text\": source,\n            \"target_text\": translation,\n            \"human_score\": row.get(\"Final Score                          (1 - lowest, 5 - highest)\"),\n            \"variance_runs\": variance_runs_for_this_entry\n        })\n\n    # Save all collected results to a single JSON file.\n    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n        json.dump(all_results, f, ensure_ascii=False, indent=2)\n        \n    print(f\"\\n--- Variance test complete. Results saved to {OUTPUT_JSON} ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T02:56:57.484945Z","iopub.execute_input":"2025-08-11T02:56:57.485234Z","iopub.status.idle":"2025-08-11T02:56:57.492931Z","shell.execute_reply.started":"2025-08-11T02:56:57.485212Z","shell.execute_reply":"2025-08-11T02:56:57.492142Z"}},"outputs":[],"execution_count":6},{"id":"a9a49616-3f2b-4bd9-bf37-aed8bc6aed60","cell_type":"code","source":"# def main():\n    \n#     # --- Configuration ---\n#     INPUT_CSV = '/kaggle/input/valset/Datasets - Human-Labeled Validation Set.csv'\n#     OUTPUT_JSON = 'baseline_validation_results.json' # Renamed for clarity\n\n#     llm = initialize_model()\n#     if not llm:\n#         print(\"Aborting due to model initialization failure.\")\n#         return\n\n#     try:\n#         df = pd.read_csv(INPUT_CSV)\n#         print(\"CSV Columns Found:\", df.columns.tolist())\n#     except FileNotFoundError:\n#         print(f\"Error: Input file not found at '{INPUT_CSV}'. Please ensure it is in the same directory.\")\n#         return\n\n#     print(f\"\\n--- Running Baseline Judge on {len(df)} entries from {INPUT_CSV} ---\")\n    \n#     all_results = []\n#     for index, row in df.iterrows():\n#         source = row.get('Source Text (English)')\n#         translation = row.get('Target Text (Filipino)')\n        \n#         if pd.isna(source) or pd.isna(translation):\n#             print(f\"Skipping row {index + 1} due to missing data.\")\n#             continue\n\n#         print(f\"--> Processing entry {index + 1}/{len(df)}...\")\n#         result = evaluate_translation(llm, source, translation)\n\n#         # Add all relevant data for easy benchmarking later\n#         all_results.append({\n#             \"entry_index\": index,\n#             \"source_text\": source,\n#             \"target_text\": translation,\n#             \"evaluation_result\": result,\n#             \"human_score\": row.get(\"Final Score                          (1 - lowest, 5 - highest)\"),\n#             \"human_explanation\": row.get(\"Rater 1 Explanation\")\n#         })\n\n#     # Save all collected results to a single JSON file.\n#     with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n#         json.dump(all_results, f, ensure_ascii=False, indent=2)\n        \n#     print(f\"\\n--- Evaluation complete. Results saved to {OUTPUT_JSON} ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T17:07:16.414440Z","iopub.execute_input":"2025-08-10T17:07:16.414818Z","iopub.status.idle":"2025-08-10T17:07:16.421438Z","shell.execute_reply.started":"2025-08-10T17:07:16.414787Z","shell.execute_reply":"2025-08-10T17:07:16.420831Z"}},"outputs":[],"execution_count":6},{"id":"6e9d1fa2-22d6-4b71-a49b-a7ce24ca754f","cell_type":"code","source":"# def main():\n#     # --- Configuration ---\n#     INPUT_CSV = '/kaggle/input/valset/Datasets - Human-Labeled Validation Set.csv'\n#     OUTPUT_JSON = 'baseline_test_results.json'\n    \n#     # Initialize the model once.\n#     llm = initialize_model()\n#     if not llm:\n#         print(\"Aborting due to model initialization failure.\")\n#         return\n    \n#     # Load the test dataset.\n#     try:\n#         df = pd.read_csv(INPUT_CSV)\n#         df.rename(columns={df.columns[0]: \"English\"}, inplace=True) # Clean up potential BOM character in first column name\n#     except FileNotFoundError:\n#         print(f\"Error: Input file not found at '{INPUT_CSV}'. Please ensure it is in the same directory.\")\n#         return\n    \n#     print(f\"\\n--- Running Baseline Judge on {len(df)} entries from {INPUT_CSV} ---\")\n    \n#     all_results = []\n#     for index, row in df.iterrows():\n#         source = row.get('English')\n#         translation = row.get('Filipino')\n    \n#         if pd.isna(source) or pd.isna(translation):\n#             continue\n    \n#         print(f\"--> Processing entry {index + 1}/{len(df)}...\")\n#         result = evaluate_translation(llm, source, translation)\n    \n#         all_results.append({\n#             \"entry_index\": index,\n#             \"source_text\": source,\n#             \"target_text\": translation,\n#             \"evaluation_result\": result\n#         })\n    \n#     # Save all collected results to a single JSON file.\n#     with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n#         json.dump(all_results, f, ensure_ascii=False, indent=2)\n        \n#     print(f\"\\n--- Evaluation complete. Results saved to {OUTPUT_JSON} ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T14:15:14.632278Z","iopub.execute_input":"2025-08-10T14:15:14.632689Z","iopub.status.idle":"2025-08-10T14:15:14.641091Z","shell.execute_reply.started":"2025-08-10T14:15:14.632658Z","shell.execute_reply":"2025-08-10T14:15:14.640319Z"}},"outputs":[],"execution_count":12},{"id":"88acfa87","cell_type":"code","source":"# def main():\n#     llm = initialize_model()\n#     if not llm:\n#         return # Exit if model fails to initialize\n\n#     print(\"\\n--- Running Baseline LLM-as-a-Judge ---\")\n\n#     # source = \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\"\n#     # translation = \"Totoo at alam ng lahat na kapag ang isang lalaking single ay maraming pera, kailangan niya talaga ng asawa.\"\n\n#     # source = \"It's raining cats and dogs.\"\n#     # translation = \"Umuulan ng pusa at aso.\"\n\n#     source = \"Fear is the mind-killer. Fear is the little-death that brings total obliteration.\"\n#     translation =  \"Ang takot ay nakakamatay ng isip. Ang takot ay parang maliit na kamatayan na nagdadala ng pagkasira.\"\n    \n#     result = evaluate_translation(llm, source, translation)\n\n#     if result:\n#         print(\"\\n--- Evaluation Complete ---\")\n#         print(f\"Source Text: {source}\")\n#         print(f\"Translation: {translation}\")\n#         print(\"\\n--- Scores ---\")\n#         for criterion, score in result.get(\"scores\", {}).items():\n#             print(f\"- {criterion.replace('_', ' ').title()}: {score}/5\")\n        \n#         print(\"\\n--- Justification ---\")\n#         print(result.get(\"explanation\", \"No explanation provided.\"))\n#         print(\"\\n-------------------------\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-10T14:14:46.964883Z","iopub.status.idle":"2025-08-10T14:14:46.965246Z","execution_failed":"2025-08-10T14:23:50.337Z"}},"outputs":[],"execution_count":null},{"id":"45a6a768","cell_type":"code","source":"if __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T02:57:03.695355Z","iopub.execute_input":"2025-08-11T02:57:03.695935Z","iopub.status.idle":"2025-08-11T03:03:29.791014Z","shell.execute_reply.started":"2025-08-11T02:57:03.695909Z","shell.execute_reply":"2025-08-11T03:03:29.790133Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92221a1ed83848d8961261d8ad2587f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8808e5c5801740ca9c7c5baedc3ac5b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab863e912074454bdb0fb22f8b33688"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54631d1712bf488c9d784d80bf4e16fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8544c05cb32c4fcdb9723b9705747918"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b07914312b343aa8dd30f82de17a3fc"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"--- Model initialized successfully. ---\n\n--- Running Baseline Judge Variance Test ---\n--- Testing 3 runs on the first 5 entries from /kaggle/input/valset/Datasets - Human-Labeled Validation Set.csv ---\n\n==================== Processing Entry 1/5 ====================\n--> Run 1/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n--> Run 2/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n--> Run 3/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n\n==================== Processing Entry 2/5 ====================\n--> Run 1/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n--> Run 2/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n--> Run 3/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n\n==================== Processing Entry 3/5 ====================\n--> Run 1/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n--> Run 2/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n--> Run 3/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n\n==================== Processing Entry 4/5 ====================\n--> Run 1/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\n","output_type":"stream"},{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"Parsing LLM response...\n--> Run 2/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n--> Run 3/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n\n==================== Processing Entry 5/5 ====================\n--> Run 1/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n--> Run 2/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n--> Run 3/3...\n\n--- Preparing evaluation for Baseline Judge ---\nSending prompt to local Llama 3 model...\nParsing LLM response...\n\n--- Variance test complete. Results saved to baseline_variance_subset_results.json ---\n","output_type":"stream"}],"execution_count":7}]}